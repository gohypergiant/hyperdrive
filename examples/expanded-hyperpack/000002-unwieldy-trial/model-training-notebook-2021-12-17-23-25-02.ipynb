{"cells": [{"cell_type": "code", "execution_count": 1, "id": "2e45e5c3", "metadata": {}, "outputs": [], "source": ["import os\n", "if os.environ[\"HYPERDRIVE_IMAGE\"].split(\"-\")[1] in (\"local\", \"dev\"):\n", "    cur_dir = os.getcwd()\n", "    os.chdir(\"/home/jovyan\")\n", "    from hdsdk import Hyperdrive\n", "    hyperdrive = Hyperdrive()\n", "    os.chdir(cur_dir)"]}, {"cell_type": "code", "execution_count": 2, "id": "4ed6703c", "metadata": {}, "outputs": [], "source": ["import os \n", "compute, environment, *flavor = os.environ[\"HYPERDRIVE_IMAGE\"].split(\"-\")\n", "flavor = flavor[-1]\n", "if flavor == \"scipy\":\n", "    flavor = \"sklearn\"\n", "print(os.environ[\"HDSDK_VERSION\"])\n", "if environment == \"test\":\n", "    from importlib.metadata import version \n", "    print(\"Installed SDK version:\", version(\"hdsdk\"))\n", "    environment = \"qa\"\n", "print(compute, environment, flavor)"]}, {"cell_type": "code", "execution_count": 3, "id": "0e678e9f", "metadata": {}, "outputs": [], "source": ["datarepo_name = \"Health Byte - Dev\"\n", "project_name = \"Customer Segmentation\""]}, {"cell_type": "code", "execution_count": 4, "id": "3572a41f", "metadata": {}, "outputs": [{"data": {"text/plain": ["'Customer Segmentation'"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["from uuid import uuid4\n", "from sklearn.model_selection import train_test_split\n", "import ipynbname\n", "unique = str(uuid4())[-6:]\n", "hyperdrive.project_name"]}, {"cell_type": "code", "execution_count": 5, "id": "f28dcaf7", "metadata": {}, "outputs": [], "source": ["assert hyperdrive.project_name == project_name\n", "print(\"Project Correctly Assigned\")"]}, {"cell_type": "code", "execution_count": 6, "id": "f6b964fb", "metadata": {}, "outputs": [], "source": ["datarepos = hyperdrive.list_datarepos()\n", "assert len(datarepos[datarepos.name == datarepo_name]) > 0\n", "print(f\"{datarepo_name} DataRepo available.\")"]}, {"cell_type": "code", "execution_count": 7, "id": "d6297bc5", "metadata": {}, "outputs": [], "source": ["hyperdrive.set_default_datarepo(datarepo_name=datarepo_name)\n", "assert hyperdrive.datarepo.name == datarepo_name\n", "print(f\"Default DataRepo '{datarepo_name}' Assigned.\")"]}, {"cell_type": "code", "execution_count": 8, "id": "15c5ec4b", "metadata": {}, "outputs": [], "source": ["datasets = hyperdrive.list_datasets()\n", "assert datasets[datasets.base_name.isin([\"ht_agg.csv\", \"user_data.csv\"])].shape[0] == 2, \"Datasets not uploaded via UI Successfully. The datasets ht_agg.csv and user_data.csv are available at https://github.com/gohypergiant/hyperdrive-sdk/tree/main/tests/data.\"\n", "print(\"Datasets available.\")"]}, {"cell_type": "code", "execution_count": 9, "id": "68232d51", "metadata": {}, "outputs": [], "source": ["hyperdrive.delete_dataset(\"merged_anonymous.parquet\")\n", "ht_agg_df = hyperdrive.load_dataset(\"ht_agg.csv\", \"csv\")\n", "user_data_df  = hyperdrive.load_dataset(\"user_data.csv\", \"csv\")\n", "user_data_df = user_data_df.set_index(\"_id\")\n", "ht_agg_df = ht_agg_df.set_index(\"_id\")\n", "merged_df = ht_agg_df.merge(user_data_df, left_index=True, right_index=True)\n", "merged_df = merged_df.drop([\"first_name\", \"last_name\"], axis=1)\n", "hyperdrive.write_dataset(merged_df, \"merged_anonymous\")\n", "datasets = hyperdrive.list_datasets()\n", "df = hyperdrive.load_dataset(\"merged_anonymous.parquet\")\n", "lifestyle_counts = df.value_counts(\"lifestyle\").to_dict()\n", "assert lifestyle_counts[\"cardio trainer\"] == 75\n", "print(\"Merged Anonyous Data Successfully Written and Read.\")"]}, {"cell_type": "code", "execution_count": 10, "id": "2275f422", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "X, y = df.drop('lifestyle',axis=1), df['lifestyle']\n", "y_dummies = pd.get_dummies(y, prefix=\"lifestyle\")\n", "\n", "if flavor == \"sklearn\":\n", "    from sklearn.ensemble import RandomForestClassifier\n", "    model = hyperdrive.get_or_create_model(model_name=f\"Customer Segmentation - Sklearn {unique}\")\n", "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, test_size=0.1)\n", "    candidate_model = RandomForestClassifier()\n", "    scorer = candidate_model.score\n", "    fit_params = {\"X\": X_train, \"y\": y_train}\n", "    \n", "elif flavor == \"xgboost\":\n", "    from xgboost import XGBClassifier\n", "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, test_size=0.1)\n", "    model = hyperdrive.get_or_create_model(model_name=f\"Customer Segmentation - XGBoost {unique}\")\n", "    candidate_model = XGBClassifier()\n", "    scorer = candidate_model.score\n", "    fit_params = {\"X\": X_train, \"y\": y_train}\n", "    \n", "elif flavor == \"tensorflow\":    \n", "    import tensorflow as tf\n", "    from tensorflow import keras \n", "    \n", "    model = hyperdrive.get_or_create_model(model_name=f\"Customer Segmentation - Tensorflow {unique}\")\n", "    X_train, X_test, y_train, y_test = train_test_split(X.values, y_dummies.values, random_state=42, test_size=0.1)\n", "    candidate_model = tf.keras.models.Sequential(\n", "            [\n", "                keras.layers.Dense(\n", "                    7, activation=\"relu\", input_shape=(4,)\n", "                ),\n", "                keras.layers.Dense(5, activation=\"relu\"),\n", "                keras.layers.Dense(3, activation=\"softmax\"),\n", "            ]\n", "        )\n", "    candidate_model.compile(\n", "            optimizer=\"adam\",\n", "            loss=\"categorical_crossentropy\",\n", "            metrics=[\"accuracy\"],\n", "        )\n", "    scorer = candidate_model.evaluate\n", "    fit_params = {\"x\": X_train, \"y\": y_train, \"epochs\": 10, \"verbose\": 0}\n", "\n", "elif flavor == \"pytorch\": \n", "    import torch\n", "    import torch.nn as nn\n", "    import torch.optim as optim\n", "    from torch.utils.data import Dataset, DataLoader\n", "    model = hyperdrive.get_or_create_model(model_name=f\"Customer Segmentation - Pytorch {unique}\")\n", "    X_train, X_test, y_train, y_test = train_test_split(X.values, y_dummies.values, random_state=42, test_size=0.1)\n", "    max_depth = 4\n", "\n", "    class Data(Dataset):\n", "        def __init__(self, X_train, y_train):\n", "            self.x=torch.from_numpy(X_train).float()\n", "            self.y=torch.from_numpy(y_train)\n", "            self.len=self.x.shape[0]\n", "        def __getitem__(self,index):      \n", "            return self.x[index], self.y[index]\n", "        def __len__(self):\n", "            return self.len\n", "\n", "    data_set=Data(X_train, y_train)\n", "    trainloader=DataLoader(dataset=data_set, batch_size=32)\n", "\n", "    class create_torch_model(nn.Module):\n", "        def __init__(self, num_feature, num_class):\n", "            super(create_torch_model, self).__init__()\n", "\n", "            self.layer_1 = nn.Linear(num_feature, max_depth)\n", "            self.layer_2 = nn.Linear(max_depth, 5)\n", "            self.layer_out = nn.Linear(5, num_class) \n", "\n", "            self.relu = nn.ReLU()\n", "            self.batchnorm1 = nn.BatchNorm1d(max_depth)\n", "            self.batchnorm2 = nn.BatchNorm1d(5)\n", "\n", "        def forward(self, inputs):\n", "            x = self.layer_1(inputs)\n", "            x = self.batchnorm1(x)\n", "            x = self.relu(x)\n", "\n", "            x = self.layer_2(x)\n", "            x = self.batchnorm2(x)\n", "            x = self.relu(x)\n", "\n", "            x = self.layer_out(x)\n", "\n", "            return x\n", "\n", "    candidate_model = create_torch_model(num_feature = 4, num_class=3)\n", "\n", "    criterion = nn.L1Loss()\n", "    optimizer = optim.Adam(candidate_model.parameters(), lr=0.1)"]}, {"cell_type": "code", "execution_count": 11, "id": "eaaa3e48", "metadata": {}, "outputs": [], "source": ["experiment = model.get_or_create_experiment(\n", "    experiment_name = f\"lifestyle_predictor_RF_{unique}\",\n", "    enable_drift_monitoring=True,\n", "    train_features=X_train,\n", "    train_target=y_train,\n", "    feature_names=list(X.columns),\n", "    data_exploration_file=\"/home/jovyan/regression-tests/00-none-smoke-test-eda.ipynb\",\n", "    data_preparation_file=\"/home/jovyan/regression-tests/00-none-smoke-test-preparation.ipynb\",\n", "    model_training_file=\"/home/jovyan/regression-tests/00-all-smoke-test.ipynb\",\n", ")"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}